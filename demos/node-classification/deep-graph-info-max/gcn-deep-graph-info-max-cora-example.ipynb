{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stellargraph.mapper import FullBatchNodeGenerator\n",
    "from stellargraph import StellarGraph\n",
    "from stellargraph.layer import GCNInfoMax\n",
    "from stellargraph import datasets\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn import preprocessing, feature_extraction, model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_loss(y_true, y_pred):\n",
    "    \n",
    "    return -tf.math.reduce_mean(tf.math.log(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "The Cora dataset consists of 2708 scientific publications classified into one of seven classes. The citation network consists of 5429 links. Each publication in the dataset is described by a 0/1-valued word vector indicating the absence/presence of the corresponding word from the dictionary. The dictionary consists of 1433 unique words."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = datasets.Cora()\n",
    "display(HTML(dataset.description))\n",
    "G, node_subjects = dataset.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subjects, test_subjects = model_selection.train_test_split(\n",
    "    node_subjects, train_size=0.1, test_size=None, stratify=node_subjects\n",
    ")\n",
    "\n",
    "target_encoding = preprocessing.LabelBinarizer()\n",
    "\n",
    "train_targets = target_encoding.fit_transform(train_subjects)\n",
    "test_targets = target_encoding.transform(test_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GCN (local pooling) filters...\n"
     ]
    }
   ],
   "source": [
    "generator = CorruptedFullBatchNodeGenerator(G,)\n",
    "gen = generator.flow(G.nodes(),)\n",
    "\n",
    "infomax = GCNInfoMax(\n",
    "    [512,], \n",
    "    activations=[tf.keras.layers.PReLU(),], \n",
    "    generator=generator, \n",
    "    bias=True,\n",
    ")\n",
    "\n",
    "x_in, x_out = infomax.unsupervised_node_model()\n",
    "\n",
    "model = Model(inputs=x_in, outputs=x_out)\n",
    "model.compile(loss=tf.nn.sigmoid_cross_entropy_with_logits, optimizer=Adam(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1 steps\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0085\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0058\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0081\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0102\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0081\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0063\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0074\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0075\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0077\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0078\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0084\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0068\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0090\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0096\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0082\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0083\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0052\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0111\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0095\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a3cd52668>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(gen, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_emb_in, x_emb_out = infomax.embedding_model(model)\n",
    "emb_model = Model(inputs=x_emb_in, outputs=x_emb_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7739950779327317"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_gen = generator.flow(test_subjects.index)\n",
    "train_gen = generator.flow(train_subjects.index)\n",
    "\n",
    "test_embeddings = emb_model.predict(test_gen)\n",
    "train_embeddings = emb_model.predict(train_gen)\n",
    "\n",
    "lr = LogisticRegression(multi_class=\"auto\", solver=\"lbfgs\")\n",
    "lr.fit(train_embeddings, train_subjects)\n",
    "\n",
    "y_pred = lr.predict(test_embeddings)\n",
    "(y_pred == test_subjects).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
