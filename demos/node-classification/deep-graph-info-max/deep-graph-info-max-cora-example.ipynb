{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stellargraph.mapper import CorruptedGraphSAGENodeGenerator\n",
    "import stellargraph as sg\n",
    "import networkx as nx\n",
    "from stellargraph import StellarGraph, StellarDiGraph\n",
    "from stellargraph.layer import GraphSAGEInfoMax\n",
    "from stellargraph import datasets\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn import preprocessing, feature_extraction, model_selection\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_loss(y_true, y_pred):\n",
    "    \n",
    "    return tf.math.reduce_mean(y_pred)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "The Cora dataset consists of 2708 scientific publications classified into one of seven classes. The citation network consists of 5429 links. Each publication in the dataset is described by a 0/1-valued word vector indicating the absence/presence of the corresponding word from the dictionary. The dictionary consists of 1433 unique words."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = datasets.Cora()\n",
    "display(HTML(dataset.description))\n",
    "G, node_subjects = dataset.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subjects, test_subjects = model_selection.train_test_split(\n",
    "    node_subjects, train_size=0.1, test_size=None, stratify=node_subjects\n",
    ")\n",
    "\n",
    "target_encoding = preprocessing.LabelBinarizer()\n",
    "\n",
    "train_targets = target_encoding.fit_transform(train_subjects)\n",
    "test_targets = target_encoding.transform(test_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 6 steps\n",
      "Epoch 1/50\n",
      "6/6 [==============================] - 1s 172ms/step - loss: 0.4952\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.4765\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.4538\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.4308\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.3874\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.3506\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.3091\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.2712\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.2640\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.2303\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.1953\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.1737\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.1573\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.1373\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.1468\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.1168\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.1081\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.1029\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.0864\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0870\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0877\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0813\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0831\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.0665\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0671\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.0776\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0798\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0651\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.0712\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.0581\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.0487\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.0474\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.0450\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.0508\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.0463\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0386\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.0455\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.0475\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.0543\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0420\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0362\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.0388\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.0405\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0476\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0401\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0413\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0328\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.0363\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0390\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a40869f60>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 50\n",
    "num_samples = [10, 5]\n",
    "\n",
    "generator = CorruptedGraphSAGENodeGenerator(G, batch_size, num_samples)\n",
    "train_gen = generator.flow(train_subjects.index, targets=np.ones(len(train_subjects)))\n",
    "\n",
    "graph_sage_infomax = GraphSAGEInfoMax([20, 20,], generator=generator)\n",
    "\n",
    "x_in, x_out = graph_sage_infomax.unsupervised_node_model()\n",
    "\n",
    "model = Model(inputs=x_in, outputs=x_out)\n",
    "model.compile(loss=info_loss, optimizer='adam')\n",
    "model.fit(train_gen, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x1a40e8d7f0>,\n",
       " <tensorflow.python.keras.engine.input_layer.InputLayer at 0x1a40e8d940>,\n",
       " <tensorflow.python.keras.engine.input_layer.InputLayer at 0x1a40e8d710>,\n",
       " <tensorflow.python.keras.layers.core.Reshape at 0x1a40e8dd30>,\n",
       " <tensorflow.python.keras.layers.core.Reshape at 0x1a40e8b5c0>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x1a40e8bcc0>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x1a40e8d6d8>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x1a40e8b630>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x1a40eef9b0>,\n",
       " <tensorflow.python.keras.engine.input_layer.InputLayer at 0x1a40e8db00>,\n",
       " <tensorflow.python.keras.engine.input_layer.InputLayer at 0x1a40e8dcc0>,\n",
       " <stellargraph.layer.graphsage.MeanAggregator at 0x1a3e40b5f8>,\n",
       " <tensorflow.python.keras.engine.input_layer.InputLayer at 0x1a40e8da58>,\n",
       " <tensorflow.python.keras.layers.core.Reshape at 0x1a409752e8>,\n",
       " <tensorflow.python.keras.layers.core.Reshape at 0x1a409b8c88>,\n",
       " <tensorflow.python.keras.layers.core.Reshape at 0x1a40f0bba8>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x1a40991be0>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x1a4099ec50>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x1a409bffd0>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x1a409d2b00>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x1a40f13198>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x1a40ee4940>,\n",
       " <stellargraph.layer.graphsage.MeanAggregator at 0x1a40505a20>,\n",
       " <tensorflow.python.keras.layers.core.Reshape at 0x1a409efdd8>,\n",
       " <tensorflow.python.keras.layers.core.Reshape at 0x1a40966668>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x1a409f80b8>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x1a40a0ea20>,\n",
       " <tensorflow.python.keras.layers.core.Lambda at 0x1a4037a390>,\n",
       " <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer at 0x1a40a91c18>,\n",
       " <tensorflow.python.keras.layers.core.Reshape at 0x1a40a01ac8>,\n",
       " <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer at 0x1a40a91898>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1a40a38b00>,\n",
       " <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer at 0x1a40a918d0>,\n",
       " <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer at 0x1a40a912e8>,\n",
       " <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer at 0x1a40a91be0>,\n",
       " <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer at 0x1a40a91390>,\n",
       " <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer at 0x1a40a91ac8>,\n",
       " <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer at 0x1a40a91400>,\n",
       " <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer at 0x1a40a91b38>,\n",
       " <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer at 0x1a40a8ab38>,\n",
       " <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer at 0x1a40aac7f0>,\n",
       " <tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer at 0x1a40a5b048>]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "6/6 [==============================] - 0s 77ms/step - loss: 0.4634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.46338745454947156"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_in, x_out = graph_sage_infomax.unsupervised_node_model()\n",
    "\n",
    "model = Model(inputs=x_in, outputs=x_out)\n",
    "model.compile(loss=info_loss, optimizer='adam')\n",
    "\n",
    "model.evaluate(train_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = generator.flow(test_subjects.index)\n",
    "test_embeddings = model.predict(test_gen)\n",
    "train_embeddings = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "626530      Probabilistic_Methods\n",
       "714975      Probabilistic_Methods\n",
       "820661            Neural_Networks\n",
       "6216       Reinforcement_Learning\n",
       "126868                 Case_Based\n",
       "                    ...          \n",
       "1115677           Neural_Networks\n",
       "1131639           Neural_Networks\n",
       "672070            Neural_Networks\n",
       "1107136        Genetic_Algorithms\n",
       "1128853             Rule_Learning\n",
       "Name: subject, Length: 2438, dtype: object"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit()\n",
    "test_targets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
